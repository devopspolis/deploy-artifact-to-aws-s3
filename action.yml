name: 'Deploy artifact to AWS S3'
description: 'Upload GitHub Actions artifacts to AWS S3 with optional extraction, support for ZIP, TAR, and prefix targeting.'
author: 'Rick Meneely <rick@devopspolis.com>'
branding:
  icon: cloud-drizzle
  color: purple

inputs:
  artifact:
    description: Name of the artifact to deploy (source)
    type: string
    required: true
  path:
    description: Filename of the artifact within the download directory
    type: string
    required: true
  script:
    description: Optional shell script to execute before uploading to S3
    type: string
    required: false
  working-directory:
    description: Directory to execute the script in (default '.')
    type: string
    required: false
    default: .
  bucket:
    description: 'AWS S3 Bucket name (optionally with prefix: bucket-name/path/to/dir)'
    type: string
    required: true
  aws-region:
    description: AWS region
    type: string
    required: false
  delete:
    description: Delete files not in source artifact
    type: boolean
    default: false
  extract-artifact:
    description: |
      If true, extracts the archive and uploads contents.
      If false, uploads archive as-is
    type: boolean
    default: true
  tags:
    description: Bucket tags (e.g. version=v1.2.0,environment=qa)
    type: string
    required: false
    default: ''
  role:
    description: IAM role to assume (optional)
    type: string
    required: false

outputs:
  bucket_arn:
    description: The AWS S3 bucket ARN
    value: ${{ steps.bucket_arn.outputs.bucket_arn }}
  uploaded_uri:
    description: Full S3 URI to the uploaded file or folder
    value: s3://${{ steps.bucketinfo.outputs.bucket_name }}/${{ steps.bucketinfo.outputs.bucket_prefix }}
  integrity_hash:
    description: MD5 hash of uploaded contents (for integrity verification)
    value: ${{ steps.hash.outputs.integrity_hash }}
  file_count:
    description: Number of files uploaded (for extracted archives)
    value: ${{ steps.upload-stats.outputs.file_count }}
  upload_size:
    description: Total size of uploaded content in bytes
    value: ${{ steps.upload-stats.outputs.upload_size }}

runs:
  using: composite
  steps:
    - name: Parse bucket and prefix
      id: bucketinfo
      shell: bash
      run: |
        full="${{ inputs.bucket }}"
        bucket_name=$(echo "$full" | cut -d'/' -f1)
        bucket_prefix=$(echo "$full" | cut -s -d'/' -f2-)
        if [ -n "$bucket_prefix" ]; then
          bucket_prefix="${bucket_prefix%/}/"
        fi
        echo "bucket_name=$bucket_name" >> $GITHUB_OUTPUT
        echo "bucket_prefix=$bucket_prefix" >> $GITHUB_OUTPUT

    - name: Validate inputs
      shell: bash
      run: |
        echo "üîç Validating inputs..."
        
        # Required inputs validation
        if [[ -z "${{ inputs.artifact }}" ]]; then
          echo "‚ùå artifact is required"
          exit 1
        fi

        if [[ -z "${{ inputs.path }}" ]]; then
          echo "‚ùå path is required"
          exit 1
        fi

        if [[ -z "${{ inputs.bucket }}" ]]; then
          echo "‚ùå bucket is required"
          exit 1
        fi

        # Validate bucket name follows AWS naming conventions
        bucket_name=$(echo "${{ inputs.bucket }}" | cut -d'/' -f1)
        if [[ ! "$bucket_name" =~ ^[a-z0-9][a-z0-9.-]{1,61}[a-z0-9]$ ]]; then
          echo "‚ùå Invalid bucket name format: $bucket_name"
          echo "üí° Bucket names must be 3-63 characters, lowercase, start/end with alphanumeric"
          exit 1
        fi

        # Validate role ARN format if provided
        if [[ -n "${{ inputs.role }}" ]] && [[ "${{ inputs.role }}" == arn:aws:iam::* ]]; then
          if [[ ! "${{ inputs.role }}" =~ ^arn:aws:iam::[0-9]{12}:role/[a-zA-Z0-9+=,.@_-]+$ ]]; then
            echo "‚ùå Invalid IAM role ARN format: ${{ inputs.role }}"
            exit 1
          fi
        fi

        # Validate tags format if provided
        if [[ -n "${{ inputs.tags }}" ]]; then
          IFS=',' read -ra PAIRS <<< "${{ inputs.tags }}"
          for pair in "${PAIRS[@]}"; do
            if [[ ! "$pair" =~ ^[^=]+=[^=]+$ ]]; then
              echo "‚ùå Invalid tag format: $pair"
              echo "üí° Tags must be in format: key=value,key2=value2"
              exit 1
            fi
          done
        fi

        # Validate script file exists if provided
        if [[ -n "${{ inputs.script }}" ]]; then
          script_file=$(echo "${{ inputs.script }}" | cut -d' ' -f1)
          if [[ ! -f "${{ inputs.working-directory }}/$script_file" ]]; then
            echo "‚ùå Script file not found: ${{ inputs.working-directory }}/$script_file"
            exit 1
          fi
        fi

        echo "‚úÖ Input validation completed successfully"

    - name: Set AWS_REGION and validate AWS CLI
      shell: bash
      run: |
        # Set AWS region with fallback hierarchy
        region="${{ inputs.aws-region }}"
        if [[ -z "$region" ]]; then
          region="${{ env.AWS_REGION }}"
        fi
        if [[ -z "$region" ]]; then
          region="${{ env.AWS_DEFAULT_REGION }}"
        fi
        if [[ -z "$region" ]]; then
          region="us-east-1"
        fi
        echo "AWS_REGION=$region" >> $GITHUB_ENV
        echo "‚úÖ Using AWS region: $region"

        # Validate AWS CLI is available
        if ! command -v aws >/dev/null 2>&1; then
          echo "‚ùå AWS CLI is not installed or not in PATH"
          exit 1
        fi

        # Validate AWS CLI version (minimum v2 recommended)
        aws_version=$(aws --version 2>&1 | cut -d/ -f2 | cut -d' ' -f1)
        echo "‚úÖ AWS CLI version: $aws_version"

    - name: Resolve role ARN if short name
      if: ${{ inputs.role }}
      id: resolve-role
      shell: bash
      run: |
        role="${{ inputs.role }}"
        if [[ "$role" != arn:aws:iam::* ]]; then
          echo "Resolving short role name to full ARN..."
          if [[ -z "$AWS_ACCOUNT_ID" ]]; then
            echo "‚ùå AWS_ACCOUNT_ID environment variable is required when using short role names"
            exit 1
          fi
          role="arn:aws:iam::${AWS_ACCOUNT_ID}:role/$role"
        fi
        echo "role_arn=$role" >> $GITHUB_OUTPUT
        echo "‚úÖ Using role: $role"

    - name: Configure AWS credentials
      if: ${{ inputs.role }}
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: ${{ steps.resolve-role.outputs.role_arn }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Set delete flag
      run: |
        echo "delete_option=$([[ '${{ inputs.delete }}' == 'true' ]] && echo '--delete')" >> $GITHUB_ENV
      shell: bash

    # https://github.com/marketplace/actions/download-a-build-artifact
    - name: Download GitHub artifact
      uses: actions/download-artifact@v4
      with:
        name: ${{ inputs.artifact }}
        path: artifact-download
      continue-on-error: false
      timeout-minutes: 10

    - name: Locate and validate artifact file
      id: locate-file
      shell: bash
      run: |
        file_path="artifact-download/${{ inputs.path }}"

        # Check if artifact download directory exists
        if [[ ! -d "artifact-download" ]]; then
          echo "‚ùå Artifact download directory not found"
          exit 1
        fi

        # Check if file exists
        if [[ ! -f "$file_path" ]]; then
          echo "‚ùå File not found: $file_path"
          echo "Available files in artifact-download:"
          find artifact-download -type f -ls 2>/dev/null || echo "No files found"
          exit 1
        fi

        # Check if file is readable
        if [[ ! -r "$file_path" ]]; then
          echo "‚ùå File is not readable: $file_path"
          exit 1
        fi

        # Validate file is not empty
        if [[ ! -s "$file_path" ]]; then
          echo "‚ùå File is empty: $file_path"
          exit 1
        fi

        # Store the validated file path
        echo "validated_file=$file_path" >> $GITHUB_OUTPUT
        echo "filename=${{ inputs.path }}" >> $GITHUB_OUTPUT

        # Show file details for debugging
        echo "‚úÖ File validation successful: ${{ inputs.path }}"
        echo "üìä File details:"
        ls -lh "$file_path"

        # Optional: Show file type information
        if command -v file >/dev/null 2>&1; then
          file "$file_path"
        fi

    - name: Extract artifact
      if: ${{ inputs.extract-artifact == 'true' }}
      shell: bash
      run: |
        mkdir -p extracted

        file="${{ steps.locate-file.outputs.validated_file }}"
        filename="${{ steps.locate-file.outputs.filename }}"

        # Determine format from filename extension (case-insensitive)
        filename_lower="${filename,,}"
        case "$filename_lower" in
          *.zip)
            format="zip"
            ;;
          *.tar.gz|*.tgz)
            format="tar.gz"
            ;;
          *.tar.bz2|*.tbz2)
            format="tar.bz2"
            ;;
          *.tar.xz|*.txz)
            format="tar.xz"
            ;;
          *.tar)
            format="tar"
            ;;
          *)
            echo "‚ùå Unsupported file extension in '$filename'"
            echo "üí° Supported formats: .zip, .tar, .tar.gz/.tgz, .tar.bz2/.tbz2, .tar.xz/.txz"
            echo "üí° Set extract-artifact to false to upload the file as-is"
            exit 1
            ;;
        esac

        echo "üì¶ Extracting $file as $format format"

        # Extract based on determined format with better error handling
        case "$format" in
          zip)
            if command -v unzip >/dev/null 2>&1; then
              if ! unzip -q "$file" -d extracted 2>/dev/null; then
                echo "‚ùå Failed to extract ZIP archive"
                echo "üí° Archive may be corrupted or password protected"
                exit 1
              fi
            else
              echo "‚ùå unzip command not found"
              exit 1
            fi
            ;;
          tar)
            if ! tar -xf "$file" -C extracted 2>/dev/null; then
              echo "‚ùå Failed to extract TAR archive"
              echo "üí° Archive may be corrupted"
              exit 1
            fi
            ;;
          tar.gz)
            if ! tar -xzf "$file" -C extracted 2>/dev/null; then
              echo "‚ùå Failed to extract TAR.GZ archive"
              echo "üí° Archive may be corrupted or gzip not available"
              exit 1
            fi
            ;;
          tar.bz2)
            if ! tar -xjf "$file" -C extracted 2>/dev/null; then
              echo "‚ùå Failed to extract TAR.BZ2 archive"
              echo "üí° Archive may be corrupted or bzip2 not available"
              exit 1
            fi
            ;;
          tar.xz)
            if ! tar -xJf "$file" -C extracted 2>/dev/null; then
              echo "‚ùå Failed to extract TAR.XZ archive"
              echo "üí° Archive may be corrupted or xz not available"
              exit 1
            fi
            ;;
          *)
            echo "‚ùå Unsupported archive format: $format"
            exit 1
            ;;
        esac

        # Verify extraction was successful
        if [[ ! -d "extracted" ]] || [[ -z "$(ls -A extracted)" ]]; then
          echo "‚ùå Extraction failed or resulted in empty directory"
          exit 1
        fi

        extracted_files=$(find extracted -type f | wc -l)
        echo "‚úÖ Successfully extracted $extracted_files files"
        
        # Store extraction stats
        echo "extracted_file_count=$extracted_files" >> $GITHUB_OUTPUT

    - name: Run pre-upload script
      if: ${{ inputs.script }}
      shell: bash
      working-directory: ${{ inputs.working-directory }}
      run: |
        ls -l
        script_file=$(echo ${{ inputs.script }} | cut -d' ' -f1)
        if [[ ! -x "${script_file}" ]]; then
           echo "‚ùå Executable script file ${script_file} not found"
           exit 1
        fi
        echo "‚úÖ Running: ${{ inputs.script }}"
        eval "${{ inputs.script }}"

    - name: Upload to S3 (extracted)
      if: ${{ inputs.extract-artifact == 'true' }}
      shell: bash
      run: |
        echo "üì§ Uploading extracted files to S3"
        
        # Retry logic for S3 operations
        max_attempts=3
        attempt=1
        
        while [[ $attempt -le $max_attempts ]]; do
          echo "üì§ Upload attempt $attempt of $max_attempts"
          
          if aws s3 sync extracted s3://${{ steps.bucketinfo.outputs.bucket_name }}/${{ steps.bucketinfo.outputs.bucket_prefix }} ${{ env.delete_option }} --region ${{ env.AWS_REGION }} --cli-read-timeout 300 --cli-connect-timeout 60; then
            echo "‚úÖ Successfully uploaded extracted files to S3"
            break
          else
            echo "‚ö†Ô∏è Upload attempt $attempt failed"
            if [[ $attempt -eq $max_attempts ]]; then
              echo "‚ùå S3 sync failed after $max_attempts attempts"
              exit 1
            fi
            echo "üîÑ Retrying in 5 seconds..."
            sleep 5
            ((attempt++))
          fi
        done

    - name: Upload to S3 (raw file)
      if: ${{ inputs.extract-artifact == 'false' }}
      shell: bash
      run: |
        file="${{ steps.locate-file.outputs.validated_file }}"
        filename="${{ steps.locate-file.outputs.filename }}"

        echo "üì§ Uploading $filename to S3"
        
        # Retry logic for S3 operations
        max_attempts=3
        attempt=1
        
        while [[ $attempt -le $max_attempts ]]; do
          echo "üì§ Upload attempt $attempt of $max_attempts"
          
          if aws s3 cp "$file" s3://${{ steps.bucketinfo.outputs.bucket_name }}/${{ steps.bucketinfo.outputs.bucket_prefix }}$filename --region ${{ env.AWS_REGION }} --cli-read-timeout 300 --cli-connect-timeout 60; then
            echo "‚úÖ Successfully uploaded $filename to S3"
            break
          else
            echo "‚ö†Ô∏è Upload attempt $attempt failed"
            if [[ $attempt -eq $max_attempts ]]; then
              echo "‚ùå S3 upload failed after $max_attempts attempts"
              exit 1
            fi
            echo "üîÑ Retrying in 5 seconds..."
            sleep 5
            ((attempt++))
          fi
        done

    - name: Add Bucket Tags
      if: ${{ inputs.tags != '' }}
      shell: bash
      run: |
        echo "üè∑Ô∏è Adding bucket tags"
        IFS=',' read -ra PAIRS <<< "${{ inputs.tags }}"
        TAGSET=""
        for pair in "${PAIRS[@]}"; do
          KEY=$(echo "$pair" | cut -d'=' -f1)
          VALUE=$(echo "$pair" | cut -d'=' -f2-)
          TAGSET="${TAGSET}{Key=${KEY},Value=${VALUE}},"
        done
        TAGSET="[${TAGSET%,}]"

        if ! aws s3api put-bucket-tagging --bucket "${{ steps.bucketinfo.outputs.bucket_name }}" --tagging "TagSet=$TAGSET" --region ${{ env.AWS_REGION }}; then
          echo "‚ùå Failed to add bucket tags"
          exit 1
        fi
        echo "‚úÖ Successfully added bucket tags"

    - name: Output bucket ARN
      id: bucket_arn
      shell: bash
      run: |
        echo "bucket_arn=arn:aws:s3:::${{ steps.bucketinfo.outputs.bucket_name }}" >> $GITHUB_OUTPUT

    - name: Generate stats and integrity hash
      id: hash
      shell: bash
      run: |
        if [[ '${{ inputs.extract-artifact }}' == 'true' ]]; then
          HASH=$(find extracted -type f -exec md5sum {} + | sort -k 2 | md5sum | awk '{print $1}')
          FILE_COUNT=$(find extracted -type f | wc -l)
          UPLOAD_SIZE=$(find extracted -type f -exec stat -f%z {} + 2>/dev/null | awk '{sum+=$1} END {print sum}' || find extracted -type f -exec stat -c%s {} + | awk '{sum+=$1} END {print sum}')
        else
          file="${{ steps.locate-file.outputs.validated_file }}"
          HASH=$(md5sum "$file" | awk '{print $1}')
          FILE_COUNT=1
          UPLOAD_SIZE=$(stat -f%z "$file" 2>/dev/null || stat -c%s "$file")
        fi
        echo "integrity_hash=$HASH" >> $GITHUB_OUTPUT
        echo "‚úÖ Generated integrity hash: $HASH"

    - name: Generate upload statistics
      id: upload-stats
      shell: bash
      run: |
        if [[ '${{ inputs.extract-artifact }}' == 'true' ]]; then
          FILE_COUNT=$(find extracted -type f | wc -l)
          UPLOAD_SIZE=$(find extracted -type f -exec stat -f%z {} + 2>/dev/null | awk '{sum+=$1} END {print sum}' || find extracted -type f -exec stat -c%s {} + | awk '{sum+=$1} END {print sum}')
        else
          file="${{ steps.locate-file.outputs.validated_file }}"
          FILE_COUNT=1
          UPLOAD_SIZE=$(stat -f%z "$file" 2>/dev/null || stat -c%s "$file")
        fi
        
        echo "file_count=$FILE_COUNT" >> $GITHUB_OUTPUT
        echo "upload_size=$UPLOAD_SIZE" >> $GITHUB_OUTPUT
        echo "‚úÖ Upload statistics: $FILE_COUNT files, $UPLOAD_SIZE bytes"
